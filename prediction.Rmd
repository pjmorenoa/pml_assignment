---
title: "Prediction Assignment Writeup"
author: "Patricio Moreno"
date: "March 06, 2016"
output: html_document
---

##Introduction

In this project, we are going to use data collected from the **Weight Lifting Exercises Dataset**, from **Groupware-LES**.(http://groupware.les.inf.puc-rio.br/). They collect information from accelerometers on different parts of the body when the subject is doing the exercise (*Quantified self movement*)

The researchers describe the experiment as follows:  
*Six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions:   
- Exactly according to the specification (Class A)   
- Throwing the elbows to the front (Class B)  
- Lifting the dumbbell only halfway (Class C)  
- Lowering the dumbbell only halfway (Class D)  
- Throwing the hips to the front (Class E)  *

In this assignment, we are going to build a model to predict the manner in which an exercise was done, based on the data collected from the accelerometer devices.  

See the project [website](http://groupware.les.inf.puc-rio.br/har#weight_lifting_exercises)

##Starting and Preprocessing

To begin the analysis, we must load the packages that we will use.

```{r results='hide', message=FALSE}
pkgs <- c("data.table","plyr","caret","randomForest",
          "gbm","rpart","foreach","doParallel","knitr")
sapply(pkgs, require, character.only=TRUE, quietly=TRUE)

```

Using `doParallel` to allow multicore parallel processing. And setting the seed.
```{r}
registerDoParallel(cores=4)
set.seed(7)
```

Download and read the datasets given in the assignment (training and testing).

```{r }
urlTra <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
urlTes <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

if (!"pml-training.csv" %in% dir(getwd())) {
        download.file(urlTra, destfile = "pml-training.csv")
}
if (!"pml-testing.csv" %in% dir(getwd())) {
        download.file(urlTes, destfile = "pml-testing.csv")
}
```

```{r}
training <- read.csv("pml-training.csv", na.strings=c("#DIV/0!"," ", "", "NA", "NAs", "NULL"))
testing <- read.csv("pml-testing.csv", na.strings=c("#DIV/0!"," ", "", "NA", "NAs", "NULL"))
```

The dataset is loaded. The last column, `classe` is the manner in which the exercise has been done. 


##Processing the datasets

As we can see, there are 19622 observations of 160 variables. There are lots of `NA` values, and there are some variables that are useless for the analysis (for example, `user_names` and all of the timestamps), we must remove them before the modeling.

```{r cache=TRUE}
tr2 <- training[, -which(names(training) %in% c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window"))]
tr2 = tr2[, colSums(is.na(tr2)) == 0]
```

Now we have to check for, and remove if there are, Near Zero variance predictors.
```{r cache=TRUE}
zv = nearZeroVar(tr2,saveMetrics=TRUE); zv
```
There are no `TRUE`on the report, so, there are no variables to remove for this reason.

```{r cache=TRUE, echo=FALSE}
for(i in c(2:ncol(tr2)-1)) {
     tr2[,i] = as.numeric(tr2[,i])
}
```

These are the variables that we will use for the modeling.
```{r eval=TRUE}
colnames(tr2)
```

##Modeling

First, we need to partition the data in `tr2` to generate a Training and a Testing group for the modeling process.
```{r}
x <- createDataPartition(tr2$classe, p=0.6, list=FALSE)
mtraining <- tr2[x,]
mtesting <- tr2[-x,]

rbind("Original dataset"=dim(tr2),
        "Training set"=dim(mtraining),
        "Testing set" = dim(mtesting))
```

###Trees

The first algorithm that we will use in this report is Prediction with Trees (using `rpart` package), using a 5 fold cross validation to prevent overfitting.
```{r cache=TRUE}
mtcontrol <- trainControl(method="cv",5)

modelT <-  train(classe ~ ., data=mtraining,
                 method="rpart", trControl=mtcontrol)
modelT

predictT <- predict(modelT, mtesting)
confusionMatrix(mtesting$classe, predictT)

```
It shows an accurracy around 50%, which is very low for prediction purposes.

###Random Forest

Now we are going to build a model using Random Forest algorithm. Again, we use a 5 fold cross validation to prevent overfitting.
```{r cache=TRUE}
mcontrol <- trainControl(method="cv", 5)

modelTr <- train(classe ~ ., data=mtraining, method="rf",
               trControl=mcontrol, ntree=500)
modelTr

predictTr <- predict(modelTr, mtesting)
confusionMatrix(mtesting$classe, predictTr)

```
As we can see, the accuracy for this model is around 99%, very good and precise for making predictions.

###General Boosted Regression model

Now we are going to train a General Boosted Regression (GBM) model (just to try another model). Same as previous model, we are using a 5 fold cross validation to prevent overfitting. 
```{r cache=TRUE, message=FALSE}
mcontrolB <- trainControl(method="cv", 5)

modelB <- train(classe ~ ., data=mtraining,
                method="gbm", trControl=mcontrolB, 
                verbose=FALSE)
modelB

predictB <- predict(modelB, mtesting)
confusionMatrix(mtesting$classe, predictB)

```
The accuracy of this model is 96%, which is very good for a prediction model, but not as Random Forest (in this assignment).



##Quiz answers

Predictions for the given testing dataset, using the Random Forest model.

```{r cache=TRUE}
answers <- predict(modelTr, testing, predict.all=TRUE)
```

```{r echo=FALSE}
a <- cbind("Question"=c(1:20),"Answer"=as.character(answers))
as.data.frame(a)
```


